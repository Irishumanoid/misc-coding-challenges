{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d10f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_data(url: str, api_key: str, write=False):\n",
    "    try:\n",
    "        res = requests.get(url=url, params={'api_key': api_key})\n",
    "        out = json.loads(res.content)\n",
    "        if write:\n",
    "            with open('./out.json', 'w+') as f:\n",
    "                json.dump(out, f, indent=4)\n",
    "        books = out['items']\n",
    "        if books and len(books) > 0:\n",
    "            book_data = []\n",
    "            for i in range(len(books)):\n",
    "                book = books[i]\n",
    "                book_out = {\n",
    "                    'title': book['volumeInfo']['title'],\n",
    "                    'author': ' '.join([a for a in book['volumeInfo']['authors']]),\n",
    "                    'publishedDate': re.match(r'^\\d{4}', book['volumeInfo']['publishedDate']).group(), # get year\n",
    "                    'pageCount': book['volumeInfo']['pageCount'],\n",
    "                    'categories': ' '.join([c for c in book['volumeInfo']['categories']]),\n",
    "                    'textSnippet': book['searchInfo']['textSnippet']\n",
    "                }\n",
    "                \n",
    "                book_out['description'] = book['volumeInfo'].get('description', '')\n",
    "                book_out['ratingsCount'] = book['volumeInfo'].get('ratingsCount', 0)\n",
    "\n",
    "                book_data.append(book_out)\n",
    "            return book_data\n",
    "        else:\n",
    "            print('no book found for query')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fae56c",
   "metadata": {},
   "source": [
    "- **Book features**: Title, author, summary, genres, keywords, theme tags.\n",
    "- **Vectorization**: Use NLP techniques like TF-IDF or embeddings (e.g., BERT) on summaries or metadata.\n",
    "- **Similarity search**: Use cosine similarity to recommend books similar to the input.\n",
    "- **Sentiment analysis**: With Text Blob polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af561f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'author', 'publishedDate', 'categories'], dtype='object')\n",
      "0    . . . I couldn&#39;t stop reading.&quot; Steph...\n",
      "1                              Ambition will fuel him.\n",
      "2    This 10th Anniversary Edition of THE HUNGER GA...\n",
      "3    Even at the age of sixteen, Katniss Everdeen k...\n",
      "4    This digital collection includes all three boo...\n",
      "5    Welcome to Panem, the world of The Hunger Game...\n",
      "6    The extraordinary, ground breaking New York Ti...\n",
      "7    Set in a dark vision of the near future, a ter...\n",
      "8    In a future North America, where the rulers of...\n",
      "9    Instructors considering this book for use in a...\n",
      "Name: textSnippet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "book_data = pd.read_csv('./books_out.csv')\n",
    "book_df = pd.DataFrame(book_data)\n",
    "for col in ['pageCount', 'ratingsCount']:\n",
    "    book_df[col] = pd.to_numeric(book_df[col], errors='coerce')\n",
    "\n",
    "str_cols = book_df.select_dtypes(exclude=['float', 'int']).columns\n",
    "str_cols = str_cols.drop(['textSnippet', 'description'])\n",
    "print(str_cols)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(book_df[str_cols]))\n",
    "encoded_cols.index = book_df.index\n",
    "book_df = pd.concat([book_df.drop(columns=str_cols), encoded_cols], axis=1)\n",
    "book_df.columns = book_df.columns.astype(str)\n",
    "print(book_df['textSnippet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3e3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(pattern=r'[^a-zA-Z]', repl=' ', string=text)\n",
    "    tokens = word_tokenize(text, language='english', preserve_line=True)\n",
    "    words = stopwords.words()\n",
    "    tokens = [t for t in tokens if t not in words]\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "book_df['textSnippetProcessed'] = book_df['textSnippet'].apply(preprocess_text)\n",
    "book_df['descriptionProcessed'] = book_df['description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df6131",
   "metadata": {},
   "source": [
    "Processing of separate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c60eb6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16559it [00:14, 1172.33it/s]\n"
     ]
    }
   ],
   "source": [
    "cols = ['id', 'name', 'genre', 'summary']\n",
    "books_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "with open('booksummaries.txt', 'r') as f:\n",
    "    reader = csv.reader(f, dialect='excel-tab')\n",
    "    for row in tqdm.tqdm(reader):\n",
    "        themes = []\n",
    "        entries = row[5].split(',')\n",
    "        for entry in entries:\n",
    "            splits = entry.split('\\\"')\n",
    "            themes.append(splits[len(splits)-2])\n",
    "        books_df.loc[len(books_df)] = {cols[0]: row[0], cols[1]: row[2], cols[2]: ' '.join([t for t in themes]), cols[3]: row[6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c8b220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>Roman \\u00e0 clef Satire Children's literature...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Science Fiction Novella Speculative fiction Ut...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Existentialism Fiction Absurdist fiction Novel</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Hard science fiction Science Fiction Speculati...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                       name  \\\n",
       "0   620                                Animal Farm   \n",
       "1   843                         A Clockwork Orange   \n",
       "2   986                                 The Plague   \n",
       "3  1756  An Enquiry Concerning Human Understanding   \n",
       "4  2080                       A Fire Upon the Deep   \n",
       "\n",
       "                                               genre  \\\n",
       "0  Roman \\u00e0 clef Satire Children's literature...   \n",
       "1  Science Fiction Novella Speculative fiction Ut...   \n",
       "2     Existentialism Fiction Absurdist fiction Novel   \n",
       "3                                                      \n",
       "4  Hard science fiction Science Fiction Speculati...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15d31c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m books_df[\u001b[33m'\u001b[39m\u001b[33mgenre\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mbooks_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenre\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m books_df[\u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m] = books_df[\u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m].apply(preprocess_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      3\u001b[39m text = re.sub(pattern=\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z]\u001b[39m\u001b[33m'\u001b[39m, repl=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, string=text)\n\u001b[32m      4\u001b[39m tokens = word_tokenize(text, language=\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m, preserve_line=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m words = \u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m tokens = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[32m      7\u001b[39m text = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/nltk/corpus/reader/wordlist.py:22\u001b[39m, in \u001b[36mWordListCorpusReader.words\u001b[39m\u001b[34m(self, fileids, ignore_lines_startswith)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids=\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     20\u001b[39m         line\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28mself\u001b[39m.raw(fileids))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_lines_startswith\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "books_df['genre'] = books_df['genre'].apply(preprocess_text)\n",
    "books_df['summary'] = books_df['summary'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'book info'], dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'genre'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'genre'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(books_df.columns)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m books_df[\u001b[33m'\u001b[39m\u001b[33mbook info\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mbooks_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenre\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + books_df[\u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m books_df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mgenre\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'genre'"
     ]
    }
   ],
   "source": [
    "print(books_df.columns)\n",
    "books_df['book info'] = books_df['genre'] + ' ' + books_df['summary']\n",
    "books_df.drop(columns=['genre', 'summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5644c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.19737192 0.13840422 ... 0.16538832 0.15853538 0.13765088]\n",
      " [0.19737192 1.         0.27824983 ... 0.09571242 0.         0.2179447 ]\n",
      " [0.13840422 0.27824983 1.         ... 0.10575205 0.11310744 0.14513411]\n",
      " ...\n",
      " [0.16538832 0.09571242 0.10575205 ... 1.         0.         0.1640478 ]\n",
      " [0.15853538 0.         0.11310744 ... 0.         1.         0.        ]\n",
      " [0.13765088 0.2179447  0.14513411 ... 0.1640478  0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def load_df(from_file = False):\n",
    "    return pd.read_csv('./books_out.csv') if from_file else books_df\n",
    "books_df = load_df(from_file = True)\n",
    "\n",
    "tf = TfidfVectorizer(analyzer = \"word\", ngram_range = (1,2), min_df = 0.1, stop_words = 'english')\n",
    "\n",
    "tfidf_matrix = tf.fit_transform(books_df['book info'])\n",
    "\n",
    "cosine_sim =  cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b06493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# doesn't work\n",
    "training_data = ' '.join([f'{books_df.loc[i, 'name']} {books_df.loc[i, 'book info']}' for i in range(len(books_df))])\n",
    "model = Word2Vec(sentences = training_data, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656e6178",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'hifriendsf' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m         recs.append(\u001b[38;5;28mlist\u001b[39m(books_df[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m])[i])\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m recs\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mget_similarity_score\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhi friendsF\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhie\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_similarity_score\u001b[39m\u001b[34m(first, second)\u001b[39m\n\u001b[32m      3\u001b[39m first = simplify(first)\n\u001b[32m      4\u001b[39m second = simplify(second)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/gensim/models/keyedvectors.py:1234\u001b[39m, in \u001b[36mKeyedVectors.similarity\u001b[39m\u001b[34m(self, w1, w2)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity\u001b[39m(\u001b[38;5;28mself\u001b[39m, w1, w2):\n\u001b[32m   1219\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cosine similarity between two keys.\u001b[39;00m\n\u001b[32m   1220\u001b[39m \n\u001b[32m   1221\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1232\u001b[39m \n\u001b[32m   1233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dot(matutils.unitvec(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m]\u001b[49m), matutils.unitvec(\u001b[38;5;28mself\u001b[39m[w2]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/gensim/models/keyedvectors.py:403\u001b[39m, in \u001b[36mKeyedVectors.__getitem__\u001b[39m\u001b[34m(self, key_or_keys)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[32m    390\u001b[39m \n\u001b[32m    391\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m.get_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/gensim/models/keyedvectors.py:446\u001b[39m, in \u001b[36mKeyedVectors.get_vector\u001b[39m\u001b[34m(self, key, norm)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    423\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[32m    424\u001b[39m \n\u001b[32m    425\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m \n\u001b[32m    445\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[32m    448\u001b[39m         \u001b[38;5;28mself\u001b[39m.fill_norms()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/gensim/models/keyedvectors.py:420\u001b[39m, in \u001b[36mKeyedVectors.get_index\u001b[39m\u001b[34m(self, key, default)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not present\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"Key 'hifriendsf' not present\""
     ]
    }
   ],
   "source": [
    "def get_similarity_score(first: str, second: str):\n",
    "    simplify = lambda txt: txt.lower().replace(' ', '')\n",
    "    first = simplify(first)\n",
    "    second = simplify(second)\n",
    "    return model.wv.similarity(first, second)\n",
    "    \n",
    "\n",
    "# TODO implement similarity search depending on whether title is close to actual title\n",
    "def recommend(title: str, top_n=10):\n",
    "    indices = pd.Series(books_df['name'])\n",
    "    titles = indices.values\n",
    "    if title not in indices.values:\n",
    "        return 'title not found in database'\n",
    "    recs = []\n",
    "    index = indices[indices == title].index[0]\n",
    "    scores = pd.Series(cosine_sim[index]).sort_values(ascending=False)\n",
    "    top_n_indices = list(scores.iloc[1:top_n].index)\n",
    "\n",
    "    for i in top_n_indices:\n",
    "        recs.append(list(books_df['name'])[i])\n",
    "    return recs\n",
    "\n",
    "get_similarity_score('hi friendsF', 'hie')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
